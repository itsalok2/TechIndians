{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed4f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "demo = pd.read_csv('demo_21q3')\n",
    "drug = pd.read_csv('drug_21q3')\n",
    "outc = pd.read_csv('outc_21q3')\n",
    "reac = pd.read_csv('reac_21q3')\n",
    "indi = pd.read_csv('indi_21q3')\n",
    "ther = pd.read_csv('ther_21q3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8920257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indi_sorted=indi.sort_values(by=['primaryid','indi_drug_seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "209e954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_sorted=drug.sort_values(by=['primaryid','drug_seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a4836bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_indi = drug_sorted.merge(indi_sorted,left_on=['primaryid','drug_seq'],right_on=['primaryid', 'indi_drug_seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e3ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_indi_ther = drug_indi.merge(ther,left_on=['primaryid','drug_seq'],right_on=['primaryid','dsg_drug_seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8d55152",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_indi_ther_outc = drug_indi_ther.merge(outc,left_on=['primaryid'],right_on=['primaryid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e84fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_indi_ther_outc_reac = drug_indi_ther_outc.merge(reac,left_on=['primaryid'],right_on=['primaryid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e036e",
   "metadata": {},
   "source": [
    "# indvisual feature are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26571d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the prod_ai frequency\n",
    "\n",
    "freq=drug_indi_ther_outc_reac['prod_ai'].value_counts(0)\n",
    "drug_indi_ther_outc_reac['freq_prod_ai'] = drug_indi_ther_outc_reac['prod_ai'].map(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "499fa0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Option 2: Ordinal severity score (recommended if you want ranking)\n",
    "severity_map = {\n",
    "    'OT': 1,\n",
    "    'HO': 2,\n",
    "    'RI': 3,\n",
    "    'DS': 4,\n",
    "    'LT': 5,\n",
    "    'DE': 6,\n",
    "    'CA': 6\n",
    "}\n",
    "\n",
    "drug_indi_ther_outc_reac['severity_score'] = drug_indi_ther_outc_reac['outc_cod'].map(severity_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51e6165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the prod_ai frequency\n",
    "\n",
    "freq=drug_indi_ther_outc_reac['prod_ai'].value_counts(0)\n",
    "drug_indi_ther_outc_reac['freq_prod_ai'] = drug_indi_ther_outc_reac['prod_ai'].map(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "910f5bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_severity = drug_indi_ther_outc_reac.groupby('prod_ai')['severity_score'].mean()\n",
    "drug_indi_ther_outc_reac['drug_severity_mean'] = drug_indi_ther_outc_reac['prod_ai'].map(drug_severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8546175",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_drug_per_person = drug_indi_ther_outc_reac.groupby('primaryid')['prod_ai'].nunique()\n",
    "drug_indi_ther_outc_reac['num_drug'] = drug_indi_ther_outc_reac['primaryid'].map(num_drug_per_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "528ae622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drug_indi_ther_outc_reac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19d4899b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['primaryid', 'drug_seq', 'role_cod', 'prod_ai', 'dechal',\n",
       "       'indi_drug_seq', 'indi_pt', 'dsg_drug_seq', 'start_dt', 'end_dt',\n",
       "       'start_dt_yrs', 'start_dt_mon', 'start_dt_date', 'end_dt_yrs',\n",
       "       'end_dt_mon', 'end_dt_date', 'outc_cod', 'pt', 'freq_prod_ai',\n",
       "       'severity_score', 'drug_severity_mean', 'num_drug'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e140c2ca",
   "metadata": {},
   "source": [
    "# function for creating one big dataframe stacke one above the other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "550f70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_faers_2021(root_folder):\n",
    "    final_tables = []\n",
    "\n",
    "    for folder in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder)\n",
    "\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        ascii_path = os.path.join(folder_path, 'ASCII')\n",
    "        if not os.path.exists(ascii_path):\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing: {folder}\")\n",
    "\n",
    "        data = {}\n",
    "\n",
    "        for file in os.listdir(ascii_path):\n",
    "            if file.endswith('.txt'):\n",
    "                key = file.replace('.txt', '').lower()\n",
    "                data[key] = pd.read_csv(\n",
    "                    os.path.join(ascii_path, file),\n",
    "                    sep='$',\n",
    "                    encoding='latin1',\n",
    "                    low_memory=False\n",
    "                )\n",
    "\n",
    "        # ðŸ”¥ Extract quarter from file names (safe)\n",
    "        # Example: demo21q1 â†’ 21q1\n",
    "        sample_key = next(iter(data.keys()))\n",
    "        quarter = sample_key[-4:]   # '21q1'\n",
    "\n",
    "        print('making table')\n",
    "        # ------------------ SELECT TABLES ------------------\n",
    "        demo = data[f'demo{quarter}'][['primaryid','i_f_code','event_dt','age','age_cod','age_grp','occp_cod','sex']]\n",
    "        drug = data[f'drug{quarter}'][['primaryid','drug_seq','role_cod','prod_ai','dechal']]\n",
    "        outc = data[f'outc{quarter}'][['primaryid','outc_cod']]\n",
    "        reac = data[f'reac{quarter}'][['primaryid','pt']]\n",
    "        ther = data[f'ther{quarter}'][['primaryid','dsg_drug_seq','start_dt','end_dt']]\n",
    "        indi = data[f'indi{quarter}'][['primaryid','indi_drug_seq','indi_pt']]\n",
    "\n",
    "        print('parsing date columns')\n",
    "        # ------------------ DATE FEATURES ------------------\n",
    "        for col in ['start_dt', 'end_dt']:\n",
    "            s = ther[col].astype(str).str.split('.', expand=True)[0]\n",
    "            ther[f'{col}_yrs'] = pd.to_numeric(s.str[:4], errors='coerce')\n",
    "            ther[f'{col}_mon'] = pd.to_numeric(s.str[4:6].where(s.str.len() >= 6), errors='coerce')\n",
    "            ther[f'{col}_date'] = pd.to_numeric(s.str[6:8].where(s.str.len() == 8), errors='coerce')\n",
    "\n",
    "        print('sorting the tables')\n",
    "        # ------------------ SORT ------------------\n",
    "        drug = drug.sort_values(['primaryid','drug_seq'])\n",
    "        indi = indi.sort_values(['primaryid','indi_drug_seq'])\n",
    "\n",
    "        print('merging the tables')\n",
    "        # ------------------ MERGE ------------------\n",
    "        merged = (\n",
    "            drug\n",
    "            .merge(indi, left_on=['primaryid','drug_seq'], right_on=['primaryid','indi_drug_seq'])\n",
    "            .merge(ther, left_on=['primaryid','drug_seq'], right_on=['primaryid','dsg_drug_seq'])\n",
    "            .merge(outc, on='primaryid')\n",
    "            .merge(reac, on='primaryid')\n",
    "        )\n",
    "\n",
    "        merged['quarter'] = quarter\n",
    "        final_tables.append(merged)\n",
    "\n",
    "    return pd.concat(final_tables, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a91ed1",
   "metadata": {},
   "source": [
    "### processing the 2021 all quaters data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "089814a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: faers_ascii_2021Q1\n",
      "making table\n",
      "parsing date columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_yrs'] = pd.to_numeric(s.str[:4], errors='coerce')\n",
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_mon'] = pd.to_numeric(s.str[4:6].where(s.str.len() >= 6), errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting the tables\n",
      "merging the tables\n",
      "Processing: faers_ascii_2021Q2\n",
      "making table\n",
      "parsing date columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_yrs'] = pd.to_numeric(s.str[:4], errors='coerce')\n",
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_mon'] = pd.to_numeric(s.str[4:6].where(s.str.len() >= 6), errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting the tables\n",
      "merging the tables\n",
      "Processing: faers_ascii_2021Q3\n",
      "making table\n",
      "parsing date columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_yrs'] = pd.to_numeric(s.str[:4], errors='coerce')\n",
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_mon'] = pd.to_numeric(s.str[4:6].where(s.str.len() >= 6), errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting the tables\n",
      "merging the tables\n",
      "Processing: faers_ascii_2021Q4\n",
      "making table\n",
      "parsing date columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_yrs'] = pd.to_numeric(s.str[:4], errors='coerce')\n",
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_mon'] = pd.to_numeric(s.str[4:6].where(s.str.len() >= 6), errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting the tables\n",
      "merging the tables\n"
     ]
    }
   ],
   "source": [
    "final_df21 = process_faers_2021('faers_ascii21')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c7485",
   "metadata": {},
   "source": [
    "### processing the 2020 all quaters data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e56592b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: faers_ascii_2020Q1\n",
      "making table\n",
      "parsing date columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_yrs'] = pd.to_numeric(s.str[:4], errors='coerce')\n",
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_mon'] = pd.to_numeric(s.str[4:6].where(s.str.len() >= 6), errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting the tables\n",
      "merging the tables\n",
      "Processing: faers_ascii_2020Q2\n",
      "making table\n",
      "parsing date columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_yrs'] = pd.to_numeric(s.str[:4], errors='coerce')\n",
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_mon'] = pd.to_numeric(s.str[4:6].where(s.str.len() >= 6), errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting the tables\n",
      "merging the tables\n",
      "Processing: faers_ascii_2020Q3\n",
      "making table\n",
      "parsing date columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_yrs'] = pd.to_numeric(s.str[:4], errors='coerce')\n",
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_mon'] = pd.to_numeric(s.str[4:6].where(s.str.len() >= 6), errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting the tables\n",
      "merging the tables\n",
      "Processing: faers_ascii_2020Q4\n",
      "making table\n",
      "parsing date columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_yrs'] = pd.to_numeric(s.str[:4], errors='coerce')\n",
      "C:\\Users\\ALOK\\AppData\\Local\\Temp\\ipykernel_14836\\3628000622.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ther[f'{col}_mon'] = pd.to_numeric(s.str[4:6].where(s.str.len() >= 6), errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting the tables\n",
      "merging the tables\n"
     ]
    }
   ],
   "source": [
    "final_df20 = process_faers_2021('faers_ascii20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6956841",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([final_df21, final_df20], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d314de",
   "metadata": {},
   "source": [
    "## adding more features and creating pipeline to do all transfomrations at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c750e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def feature_engineering_pipeline(df):  \n",
    "    print(\"Starting feature engineering...\")\n",
    "    print(f\"Initial shape: {df.shape}\")\n",
    "    \n",
    "    df = df[~df['indi_pt'].str.contains('Product used for unknown indication', na=False)]\n",
    "    df = df[~df['pt'].str.contains('Off label use', na=False)]\n",
    "    print(f\"After removing unknown indications: {df.shape}\")\n",
    "    \n",
    "    # 2. FILTER TOP CATEGORIES\n",
    "    # For prod_ai (active substance)\n",
    "    top_prod_ai = df['prod_ai'].value_counts().head(30).index\n",
    "    df = df[df['prod_ai'].isin(top_prod_ai)]\n",
    "    print(f\"After filtering top 30 prod_ai: {df.shape}\")\n",
    "    \n",
    "    # For indi_pt (drug indication)\n",
    "    top_indi = df['indi_pt'].value_counts().head(30).index\n",
    "    df = df[df['indi_pt'].isin(top_indi)]\n",
    "    print(f\"After filtering top 30 indications: {df.shape}\")\n",
    "    \n",
    "    # For pt (reaction)\n",
    "    top_reactions = df['pt'].value_counts().head(30).index\n",
    "    df = df[df['pt'].isin(top_reactions)]\n",
    "    print(f\"After filtering top 30 reactions: {df.shape}\")\n",
    "    \n",
    "    # 3. ENCODE CATEGORICAL VARIABLES \n",
    "    le_prod = LabelEncoder()\n",
    "    le_indi = LabelEncoder()\n",
    "    le_pt = LabelEncoder()\n",
    "    le_role = LabelEncoder()\n",
    "    \n",
    "    df['prod_ai_encoded'] = le_prod.fit_transform(df['prod_ai'].fillna('UNKNOWN'))\n",
    "    df['indi_pt_encoded'] = le_indi.fit_transform(df['indi_pt'].fillna('UNKNOWN'))\n",
    "    df['pt_encoded'] = le_pt.fit_transform(df['pt'].fillna('UNKNOWN'))\n",
    "    df['role_cod_encoded'] = le_role.fit_transform(df['role_cod'].fillna('UNKNOWN'))\n",
    "    \n",
    "    # 4. CREATE SEVERITY FEATURES\n",
    "    # Map outcome codes to numeric severity\n",
    "    severity_map = {\n",
    "        'OT': 1,  # Other\n",
    "        'RI': 2,  # Required Intervention\n",
    "        'HO': 3,  # Hospitalization\n",
    "        'DS': 4,  # Disability\n",
    "        'LT': 5,  # Life-threatening\n",
    "        'CA': 6,  # Congenital Anomaly\n",
    "        'DE': 6   # Death\n",
    "    }\n",
    "    df['severity_score'] = df['outc_cod'].map(severity_map).fillna(1)\n",
    "    \n",
    "    # 5. CREATE DRUG-LEVEL AGGREGATIONS\n",
    "    # Drug frequency (how common is this drug in adverse events)\n",
    "    drug_freq = df.groupby('prod_ai').size()\n",
    "    df['drug_frequency'] = df['prod_ai'].map(drug_freq)\n",
    "    \n",
    "    # Average severity for each drug\n",
    "    drug_severity = df.groupby('prod_ai')['severity_score'].mean()\n",
    "    df['drug_avg_severity'] = df['prod_ai'].map(drug_severity)\n",
    "    \n",
    "    # 6. CREATE PATIENT-LEVEL FEATURES\n",
    "    # Number of drugs per patient (polypharmacy indicator)\n",
    "    drugs_per_patient = df.groupby('primaryid')['prod_ai'].nunique()\n",
    "    df['num_drugs'] = df['primaryid'].map(drugs_per_patient)\n",
    "    \n",
    "    # Number of reactions per patient\n",
    "    reactions_per_patient = df.groupby('primaryid')['pt'].nunique()\n",
    "    df['num_reactions'] = df['primaryid'].map(reactions_per_patient)\n",
    "    \n",
    "    # 7. CREATE TEMPORAL FEATURES (from start_dt fields)\n",
    "    df[['start_dt_yrs', 'start_dt_mon', 'start_dt_date', 'end_dt_yrs','end_dt_mon', 'end_dt_date']] = df[['start_dt_yrs', 'start_dt_mon', 'start_dt_date', 'end_dt_yrs','end_dt_mon', 'end_dt_date']].fillna(0)\n",
    "            \n",
    "    yrs_days = df['end_dt_yrs'] - df['start_dt_yrs']\n",
    "    mon_days = df['end_dt_mon'] - df['start_dt_mon']\n",
    "    date_days= df['end_dt_date'] - df['start_dt_date']\n",
    "    df['treatment_duration'] = yrs_days*365 + mon_days*30 + date_days*1\n",
    "    df['treatment_duration'] = df['treatment_duration'].fillna(0)\n",
    "    \n",
    "    # Convert start year to age of report (relative to 2021)\n",
    "    df['report_age_years'] = 2021 - df['start_dt_yrs'].fillna(2021)\n",
    "    \n",
    "    # 8. CREATE INTERACTION FEATURES\n",
    "    # Drug-indication interaction \n",
    "    df['drug_indication_combo'] = (df['prod_ai_encoded'].astype(str) + '_' + \n",
    "                                    df['indi_pt_encoded'].astype(str))\n",
    "    \n",
    "    # 9. HANDLE DECHAL (dechallenge) -  binary features\n",
    "    # Map to binary: Y=1, N=0, U/NaN=0\n",
    "    df['dechal_binary'] = df['dechal'].map({'Y': 1, 'N': 0}).fillna(0)\n",
    "    \n",
    "    # 10. CREATE ROLE-BASED FEATURES\n",
    "    # Primary suspect (PS) vs others\n",
    "    df['is_primary_suspect'] = (df['role_cod'] == 'PS').astype(int)\n",
    "    df['is_secondary_suspect'] = (df['role_cod'] == 'SS').astype(int)\n",
    "    df['is_concomitant'] = (df['role_cod'] == 'C').astype(int)\n",
    "    \n",
    "    # 11. DROP COLUMNS WITH TOO MANY NULLS (>30% similar to final code)\n",
    "    null_pct = df.isnull().sum() / len(df)\n",
    "    cols_to_drop = null_pct[null_pct > 0.3].index.tolist()\n",
    "    print(f\"Dropping columns with >30% nulls: {cols_to_drop}\")\n",
    "    df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    # 12. FINAL CLEANUP\n",
    "    # Drop remaining nulls in key columns\n",
    "    df = df.dropna(subset=['prod_ai_encoded', 'indi_pt_encoded', \n",
    "                           'pt_encoded', 'severity_score'])\n",
    "    \n",
    "    print(f\"Final shape after feature engineering: {df.shape}\")\n",
    "    \n",
    "    return df, {\n",
    "        'prod_ai_encoder': le_prod,\n",
    "        'indi_pt_encoder': le_indi,\n",
    "        'pt_encoder': le_pt,\n",
    "        'role_cod_encoder': le_role\n",
    "    }\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "805baf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature engineering...\n",
      "Initial shape: (21126086, 19)\n",
      "After removing unknown indications: (17010568, 19)\n",
      "After filtering top 30 prod_ai: (4643529, 19)\n",
      "After filtering top 30 indications: (3652039, 19)\n",
      "After filtering top 30 reactions: (1260833, 19)\n",
      "Dropping columns with >30% nulls: []\n",
      "Final shape after feature engineering: (1260833, 35)\n"
     ]
    }
   ],
   "source": [
    "df_engineered, encoders = feature_engineering_pipeline(df=final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e080438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save encoders for future use\n",
    "with open('encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(encoders, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36c09286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_features(df):\n",
    "    \"\"\"\n",
    "    Create the final feature set for modeling (similar to VectorAssembler in final code)\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_columns = [\n",
    "        'prod_ai_encoded',\n",
    "        'indi_pt_encoded', \n",
    "        'role_cod_encoded',\n",
    "        'drug_frequency',\n",
    "        'drug_avg_severity',\n",
    "        'num_drugs',\n",
    "        'num_reactions',\n",
    "        'treatment_duration',\n",
    "        'dechal_binary',\n",
    "        'is_primary_suspect',\n",
    "        'is_secondary_suspect',\n",
    "        'is_concomitant'\n",
    "    ]\n",
    "    \n",
    "    # Filter to only include columns that exist\n",
    "    feature_columns = [col for col in feature_columns if col in df.columns]\n",
    "    \n",
    "    X = df[feature_columns].copy()\n",
    "    \n",
    "    # Target variable (reaction type or severity)\n",
    "    y_reaction = df['pt_encoded'].copy()  # Predicting reaction type\n",
    "    y_severity = df['severity_score'].copy()  # Predicting severity\n",
    "    \n",
    "    print(f\"Feature matrix shape: {X.shape}\")\n",
    "    print(f\"Features used: {feature_columns}\")\n",
    "    \n",
    "    return X, y_reaction, y_severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27722b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (1260833, 12)\n",
      "Features used: ['prod_ai_encoded', 'indi_pt_encoded', 'role_cod_encoded', 'drug_frequency', 'drug_avg_severity', 'num_drugs', 'num_reactions', 'treatment_duration', 'dechal_binary', 'is_primary_suspect', 'is_secondary_suspect', 'is_concomitant']\n"
     ]
    }
   ],
   "source": [
    "X, y_reaction, y_severity = create_model_features(df_engineered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afe09baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('X_features.csv', index=False)\n",
    "y_reaction.to_csv('y_reaction.csv', index=False)\n",
    "y_severity.to_csv('y_severity.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6abdaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
